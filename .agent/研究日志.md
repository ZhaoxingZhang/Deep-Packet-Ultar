# 研究背景

*   **核心课题**: 面向开放集识别的增量式加密流量分类技术的研究与实现。
*   **关键挑战**: 
    1.  **开放集识别**: 模型需要有效识别并归类从未见过的新流量类别（即“未知类”）。
    2.  **数据不均衡**: 在真实网络环境中，各类应用的流量数据通常是不均衡的，模型需要在此情况下依然保持稳健的性能。
    3.  **增量识别**: 模型可以适应新增的流量类型，并在少量样本的情况下习得一定的分类准确性 

# 指令
* 所有python都要在 conda activate deep_packet 之后执行

# 进展
## 日期：2025年10月24日 21:40
### 当前研究进展总结：
现在在基于[Deep-Packet](https://github.com/ZhaoxingZhang/Deep-Packet-Ultar)这个模型的基础上进行改进，以达到提升模型对未知流量的开放集识别能力，并改善其增量识别能力的目标，但是我这段时间做了多种尝试，主要有这些：

   1. 增加注意力机制：在ResNet模型中引入SEBlock注意力机制后，模型表现大幅下降，宏平均F1分数从基准的0.72降低至0.52。
   2. 优化数据与算法：尝试了两种主流方法来解决数据不均衡问题，但效果均不理想：
       * 使用SMOTE技术进行数据增强，导致模型严重过拟合，宏平均F1分数骤降至0.31。
       * 改用Focal Loss损失函数，模型性能完全崩溃，宏平均F1分数仅为0.09。
   3. 尝试混合专家（MoE）架构：这是唯一获得部分成功的尝试。虽然总体准确率从90.8%下降到87.2%，宏平均F1分数从0.72提升到了0.78

这些优化尝试都没有超过基准模型的表现
Deep-Packet作为基准感觉是一个比较简单的模型，但是它在加密流量分析上表现很好，准确率能有96%以上，在开放集识别、增量识别上表现也很好，并且加了好几种间接层都会降低它的表现
这个基准模型的架构是一个基于`ResNet1d`的深度残差网络。其核心是一个包含16个残差块（`BasicBlock`）的1D卷积网络，每个残差块有两层卷积。在残差网络之后，它还连接了三个全连接层，用于最终的分类决策

### 对当前进展的反思
- 数据集是什么样子？：目前用的是ISCX VPN-nonVPN 2016数据集，数据预处理直接用的Deep-Packet提供的方法
- 提取了哪些特征？贡献度如何：
    - 它处理数据的时候没有提取特征，直接把网络包从IP头开始的前1500个字节转化成固定长度为1500的向量了
    - 那可能不行，他们的方法，数据和特征，肯定是他们的比较优。这个策略是不对的，第一步需要先构造专用场景的数据集，不能在他那上面硬做了
    - 把 IP 头和端口混淆之后试下？随机化之后
- 我也做了一些处理，比如我把数据集一个类（Facebook）之外其他类的样本数量都降低到1/10，构建的倾斜数据集上表现还是基准模型更好
    - 这种处理是对的
- 降低到 1/10 之后，每个类是多大规模：
    - 它这个数据集本身类不均衡，大致上top3的类几百万，少数类几千这样
    - 几千还是太多了，现在 few-shot 场景很极端，几十这样
- 这些数据包本身有没有明文字节特征
    - 目前用的数据集有明文特征
    - deep packet 这种流量编码方式非常适合提取明文特征，难怪（基准模型的分类效果那么好）

### 下一步研究计划
- 寻找不带有明文信息的数据集、或者自行编写数据预处理脚本，将数据集中的IP 头和端口作混淆处理
- 在不带有明文信息的数据集上进行训练，获取到Deep-Packet真实的加密流量分类表现
- 验证MoE框架的分类表现，并修改框架使其能更灵活的改变架构和适应分类任务（例如增加专家以实现增量分类）

## 日期：2025年10月25日 00:52
### 核心任务：数据集净化与预处理流程强化

本次工作的核心目标是解决“下一步研究计划”中提出的数据集可能存在明文信息泄露的问题。我们通过一系列分析、编码与调试，强化了数据预处理流程，以确保模型训练于更“纯净”的数据之上。

#### 1. 数据污染分析

根据研究计划，我们首先需要确认数据集中是否存在信息泄露。我们以`NonVPN-PCAPs-01/aim_chat_3a.pcap`文件作为样本进行了分析。

- **初步分析**：我们使用`tcpdump`工具检查了数据包内容。分析确认了IP地址和端口号是明文的，这可能导致模型学习到错误的“捷径”。
- **深入分析**：在用户的引导下，我们进一步分析了载荷（payload）部分。我们发现，除了IP和端口，数据集中还存在大量基础设施类协议的明文包，如`ARP`, `DNS`, `NTP`, `NBNS`, `LLMNR`等。这些协议与目标应用流量无关，但具有极强的模式特征，会对模型造成严重干扰。

#### 2. 预处理脚本强化

在明确了污染源后，我们对预处理流程进行了一系列增强，主要集中在`preprocessing.py`和`utils.py`两个文件。

- **IP地址混淆**：通过阅读`preprocessing.py`，我们发现脚本中已有名为`mask_ip`的函数，它会将IP地址置零。这表明IP泄露问题在现有流程中已得到处理。

- **端口混淆**：
    - 我们讨论了多种端口混淆策略。代理最初提出了一个基于确定性随机映射的复杂方案。
    - **用户决策**：用户提出一个更简单、更彻底的“归零”方案。我们采纳了这个建议。
    - **实现**：我们为`preprocessing.py`添加了`mask_ports_to_zero`函数，并增加`--mask-ports`命令行标志来控制此功能的开关。

- **基础设施协议过滤**：
    - 这是本次净化工作的关键一步。我们统一了意见，认为应从数据集中彻底剔除`ARP`, `DNS`, `NTP`, `NBNS`, `LLMNR`这些无关协议。
    - **实现**：我们将所有过滤逻辑集中到了`utils.py`的`should_omit_packet`函数中。通过扩展此函数，我们现在可以有效地在预处理的最早阶段就丢弃这些“噪声”数据包。

#### 3. 数据集结构探索

在处理数据泄露问题的过程中，我们对数据集的内部结构进行了对比分析。

- **对比样本**：我们检查了`vpn_aim_chat1b.pcap` (VPN流量) 和 `AUDIO_spotifygateway.pcap` (Tor流量)。
- **结论**：分析证实，VPN和Tor的pcap文件远比非VPN的“纯净”。由于VPN/Tor的隧道封装机制，上述所有基础设施“噪声”协议均不可见。这一发现为后续实验的数据选择提供了重要参考：**优先使用VPN和Tor数据集可以规避大部分数据污染问题**。

#### 4. 训练流程调试

在用户完成了数据预处理后，我们进入了创建训练/测试集的步骤，但遇到了`ValueError: max() arg is an empty sequence`的报错。

- **问题定位**：通过检查`create_train_test_set.py`的日志和代码，我们发现错误是由于Spark未能读取到任何数据，导致标签列表为空。
- **原因分析**：根本原因在于该脚本默认的`json`读取路径模式 (`/*.json.gz`) 过于简单，无法匹配`preprocessing.py`生成的分块文件名（如 `..._part_0000.json.gz`）。
- **解决方案**：我们通过将文件匹配模式修改为更健壮的递归模式 (`/**/*.json.gz`)，解决了这个问题，使得Spark能够正确发现并加载所有数据分块。

#### 总结

经过本次协作，我们：
1.  **确认并解决了**数据集中存在的多类明文信息泄露问题。
2.  **强化了**数据预处理脚本，使其能够过滤无关协议并提供端口混淆选项。
3.  **明确了**不同子数据集（VPN/Tor vs Non-VPN）的纯净度差异。
4.  **修复了**数据加载脚本中的一个关键Bug，打通了从预处理到训练的数据流程。

当前，数据净化和流程调试工作已完成，可以正式进入模型训练阶段。

## 日期：2025年10月25日
### 核心任务：打通并完善“预处理-训练-评估”全流程

在昨日完成数据净化方案的基础上，今日我们致力于打通整个实验流程，并修复了流程中遇到的多个关键Bug。

#### 1. 调试 `create_train_test_set.py` 脚本

在运行生成训练/测试集的脚本时，我们遇到了两个连续的错误，并逐一解决。

- **错误一：`ValueError: max() arg is an empty sequence`**
    - **定位**：经查，该错误是由于Spark未能从指定的`processed_data/vpn`目录中加载任何`.json.gz`文件，导致标签列表为空。
    - **修复**：我们发现脚本中加载文件的路径模式`/*.json.gz`无法匹配`preprocessing.py`生成的分块文件名。通过将其修改为递归的、更健壮的`/**/*.json.gz`模式，成功解决了文件加载问题。

- **错误二：`ValueError: cannot convert float NaN to integer`**
    - **定位**：此错误在使用`--fraction 0.01`进行小比例采样时出现。原因是采样后部分类别的样本仅剩1个，该样本被分配到测试集后，导致训练集中该类别为空，后续的欠采样逻辑在计算空列表的最小值时出错。
    - **修复**：我们在`split_train_test`函数中增加了安全检查，在执行欠采样逻辑前，判断训练集是否为空。如果为空，则跳过欠采样，从而修复了该错误。

#### 2. 完善 `create_train_test_set.py` 的易用性

在调试过程中，用户反馈`--experiment_type`参数的命名与其实际行为不符，易造成混淆。例如`exp2`会默认执行欠采样，使其训练集变为均衡，这一点从参数名上完全看不出来。

- **初步方案**：代理提议进行一次彻底的重构，废弃`--experiment_type`，将其拆分为`--balance-train`等一系列原子化的命令行参数。
- **最终决策**：用户经过考虑，认为重构风险较大，提出了一个更稳妥的方案：保留现有结构，但增加一个新的实验类型，并完善文档。
- **实现**：
    1.  **新增实验类型**：我们添加了`--experiment_type imbalanced`选项。此选项会执行标准的训练/测试集分割，但**不进行任何欠采样**，完全保留数据的原始分布，满足了用户的核心需求。
    2.  **完善文档**：我们在脚本文件顶部增加了一段详尽的注释，详细说明了每一种`experiment_type`（包括`exp2`会使训练集均衡，`exp3`会使全局数据均衡等）的具体行为和适用场景，彻底解决了参数不明确的问题。

#### 3. 修复训练与评估脚本

在准备好数据并开始训练后，我们发现并修复了后续脚本中的两个关键Bug。

- **修复 `train_resnet.py`**：用户指出，为`traffic`任务调用`train_traffic_classification_resnet_model`函数时，`validation_split`参数没有被正确处理。经检查`ml/utils.py`，发现该函数确实遗漏了此参数的接收和传递。我们参照正确的实现，为其补全了逻辑。

- **修复 `evaluation.py`**：在生成最终评估指令时，通过阅读代码发现，该脚本对`--model_type resnet`的处理逻辑存在`NotImplementedError`，即作者并未完成标准ResNet模型的加载功能。
    - **实现**：我们参照`ml/utils.utils`中的加载逻辑，为`evaluation.py`补全了加载`ResNet`模型的代码，使其能够正常工作。

#### 总结

经过今日的密集协作，我们成功打通了从数据生成到模型评估的完整链路。通过修复多个脚本中的关键Bug并极大地改善了数据生成脚本的清晰度和易用性，现在整个实验流程已准备就绪，可以随时开始正式的模型训练和评估。

## 日期：2025年11月1日

### 核心任务：设计并实现简化的混合专家（MoE）系统，以提升对少数类的识别能力

#### 1. 确定少数类

*   **目标**：从新的VPN流量数据集中识别出基准模型表现不佳的少数类。
*   **过程**：
    *   创建 `check_labels.py` 脚本，用于分析 `processed_data/vpn` 目录下预处理数据的 `traffic_label` 分布。
    *   解决了 `pyspark` 环境配置、`psutil` 依赖缺失、`conda run` 管道问题以及文件读取方式等一系列技术障碍。
    *   分析发现 `app_label` 字段在VPN数据中为空，因此将分析重点转向 `traffic_label`。
*   **结论**：根据 `traffic_label` 的分布统计，确定标签 `5` ("VPN: Chat") 和 `7` ("VPN: Email") 为少数类。

#### 2. 构建少数类专家数据集

*   **目标**：为少数类专家模型准备专门的训练/测试数据集。
*   **过程**：
    *   重构 `create_train_test_set.py` 脚本，使其可以通过 `--minority-classes` 命令行参数动态指定少数类标签，增强了脚本的灵活性。
    *   成功运行修改后的脚本，在 `train_test_data/traffic_minority_expert` 目录下生成了包含类别5和7的数据集。

#### 3. 融合策略的探索与验证

*   **用户初始设想**：通过基准模型的预测置信度来判断是否“模糊”，从而决定是否将样本路由给少数类专家。
*   **验证过程**：
    *   创建 `analyze_baseline_confidence.py` 脚本，用于分析基准模型在少数类样本上的预测置信度。
    *   解决了脚本的参数传递问题（从stdin改为命令行参数）。
    *   运行分析脚本，得到关键发现。
*   **验证结果**：分析显示，基准模型在错误分类少数类样本时，平均置信度约为60.63%。这表明模型并非“不确定”，而是“自信地犯错”。因此，简单依赖置信度阈值来判断“模糊”并触发专家模型的方案，效果可能不佳。

#### 4. 确定并实施模型融合（Ensemble）方案

*   **策略调整**：鉴于基准模型“自信地犯错”的特性，我们放弃了基于置信度阈值的路由方案，并排除了基于预测标签的路由方案（因为基准模型从不预测少数类）。
*   **最终选择**：决定采用**模型融合（Ensemble）**方案，即同时运行基准模型和少数类专家模型，并通过加权平均融合它们的预测概率。
*   **实现**：
    *   对 `evaluation.py` 脚本进行了大规模重构，增加了 `--eval-mode` 参数，支持 `standard` 和 `ensemble` 两种评估模式。
    *   在 `ensemble` 模式下，脚本能够加载基准模型和少数类专家模型，正确处理少数类标签的映射，并实现概率的加权融合。

#### 总结

今天的工作成功地识别了新数据集中的少数类，构建了相应的专家数据集，并通过实证分析验证了基准模型在少数类上的行为。基于这些发现，我们最终确定并实现了模型融合的评估框架。下一步将是使用这个框架对融合模型进行实际评估。

## 日期：2025年10月31日
基准模型表现：
  --- Evaluation Results ---
  Accuracy: 0.9633

  Classification Report:
                precision    recall  f1-score   support

             5       0.00      0.00      0.00       215
             6       0.75      0.91      0.82      1034
             7       0.00      0.00      0.00        65
             8       1.00      0.99      1.00      4408
             9       0.99      0.98      0.98      1089
            10       0.97      0.98      0.98      9476

      accuracy                           0.96     16287
     macro avg       0.62      0.64      0.63     16287
  weighted avg       0.95      0.96      0.96     16287
  minority_weight = 0.15时的表现：
  --- Evaluation Results ---
  Accuracy: 0.9641

  Classification Report:
                precision    recall  f1-score   support

             5       0.29      0.07      0.11       215
             6       0.76      0.90      0.82      1034
             7       0.71      0.08      0.14        65
             8       1.00      0.99      1.00      4408
             9       0.99      0.98      0.98      1089
            10       0.98      0.98      0.98      9476

      accuracy                           0.96     16287
     macro avg       0.79      0.67      0.67     16287
  weighted avg       0.96      0.96      0.96     16287
  minority_weight=0.1时
  --- Evaluation Results ---
  Accuracy: 0.9634

  Classification Report:
                precision    recall  f1-score   support

             5       0.20      0.01      0.02       215
             6       0.75      0.90      0.82      1034
             7       0.67      0.03      0.06        65
             8       1.00      0.99      1.00      4408
             9       0.99      0.98      0.98      1089
            10       0.97      0.98      0.98      9476

      accuracy                           0.96     16287
     macro avg       0.76      0.65      0.64     16287
  weighted avg       0.96      0.96      0.96     16287
  minority_weight=0.2时
  --- Evaluation Results ---
  Accuracy: 0.9592

  Classification Report:
                precision    recall  f1-score   support

             5       0.19      0.23      0.21       215
             6       0.77      0.88      0.82      1034
             7       0.86      0.18      0.30        65
             8       1.00      0.99      1.00      4408
             9       0.99      0.98      0.98      1089
            10       0.98      0.97      0.98      9476

      accuracy                           0.96     16287
     macro avg       0.80      0.71      0.71     16287
  weighted avg       0.96      0.96      0.96     16287

教师对下一步的指导：
