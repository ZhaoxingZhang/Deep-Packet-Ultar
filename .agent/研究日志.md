
# 研究背景

*   **核心课题**: 面向开放集识别的增量式加密流量分类技术的研究与实现。
*   **关键挑战**: 
    1.  **开放集识别**: 模型需要有效识别并归类从未见过的新流量类别（即“未知类”）。
    2.  **数据不均衡**: 在真实网络环境中，各类应用的流量数据通常是不均衡的，模型需要在此情况下依然保持稳健的性能。
    3.  **增量识别**: 模型可以适应新增的流量类型，并在少量样本的情况下习得一定的分类准确性 

# 进展
## 日期：2025年10月24日 21:40
### 当前研究进展总结：
现在在基于[Deep-Packet](https://github.com/ZhaoxingZhang/Deep-Packet-Ultar)这个模型的基础上进行改进，以达到提升模型对未知流量的开放集识别能力，并改善其增量识别能力的目标，但是我这段时间做了多种尝试，主要有这些：

   1. 增加注意力机制：在ResNet模型中引入SEBlock注意力机制后，模型表现大幅下降，宏平均F1分数从基准的0.72降低至0.52。
   2. 优化数据与算法：尝试了两种主流方法来解决数据不均衡问题，但效果均不理想：
       * 使用SMOTE技术进行数据增强，导致模型严重过拟合，宏平均F1分数骤降至0.31。
       * 改用Focal Loss损失函数，模型性能完全崩溃，宏平均F1分数仅为0.09。
   3. 尝试混合专家（MoE）架构：这是唯一获得部分成功的尝试。虽然总体准确率从90.8%下降到87.2%，宏平均F1分数从0.72提升到了0.78

这些优化尝试都没有超过基准模型的表现
Deep-Packet作为基准感觉是一个比较简单的模型，但是它在加密流量分析上表现很好，准确率能有96%以上，在开放集识别、增量识别上表现也很好，并且加了好几种间接层都会降低它的表现
这个基准模型的架构是一个基于`ResNet1d`的深度残差网络。其核心是一个包含16个残差块（`BasicBlock`）的1D卷积网络，每个残差块有两层卷积。在残差网络之后，它还连接了三个全连接层，用于最终的分类决策

### 对当前进展的反思
- 数据集是什么样子？：目前用的是ISCX VPN-nonVPN 2016数据集，数据预处理直接用的Deep-Packet提供的方法
- 提取了哪些特征？贡献度如何：
    - 它处理数据的时候没有提取特征，直接把网络包从IP头开始的前1500个字节转化成固定长度为1500的向量了
    - 那可能不行，他们的方法，数据和特征，肯定是他们的比较优。这个策略是不对的，第一步需要先构造专用场景的数据集，不能在他那上面硬做了
    - 把 IP 头和端口混淆之后试下？随机化之后
- 我也做了一些处理，比如我把数据集一个类（Facebook）之外其他类的样本数量都降低到1/10，构建的倾斜数据集上表现还是基准模型更好
    - 这种处理是对的
- 降低到 1/10 之后，每个类是多大规模：
    - 它这个数据集本身类不均衡，大致上top3的类几百万，少数类几千这样
    - 几千还是太多了，现在 few-shot 场景很极端，几十这样
- 这些数据包本身有没有明文字节特征
    - 目前用的数据集有明文特征
    - deep packet 这种流量编码方式非常适合提取明文特征，难怪（基准模型的分类效果那么好）

### 下一步研究计划
- 寻找不带有明文信息的数据集、或者自行编写数据预处理脚本，将数据集中的IP 头和端口作混淆处理
- 在不带有明文信息的数据集上进行训练，获取到Deep-Packet真实的加密流量分类表现
- 验证MoE框架的分类表现，并修改框架使其能更灵活的改变架构和适应分类任务（例如增加专家以实现增量分类）

## 日期：2025年10月25日 00:52
### 核心任务：数据集净化与预处理流程强化

本次工作的核心目标是解决“下一步研究计划”中提出的数据集可能存在明文信息泄露的问题。我们通过一系列分析、编码与调试，强化了数据预处理流程，以确保模型训练于更“纯净”的数据之上。

#### 1. 数据污染分析

根据研究计划，我们首先需要确认数据集中是否存在信息泄露。我们以`NonVPN-PCAPs-01/aim_chat_3a.pcap`文件作为样本进行了分析。

- **初步分析**：我们使用`tcpdump`工具检查了数据包内容。分析确认了IP地址和端口号是明文的，这可能导致模型学习到错误的“捷径”。
- **深入分析**：在用户的引导下，我们进一步分析了载荷（payload）部分。我们发现，除了IP和端口，数据集中还存在大量基础设施类协议的明文包，如`ARP`, `DNS`, `NTP`, `NBNS`, `LLMNR`等。这些协议与目标应用流量无关，但具有极强的模式特征，会对模型造成严重干扰。

#### 2. 预处理脚本强化

在明确了污染源后，我们对预处理流程进行了一系列增强，主要集中在`preprocessing.py`和`utils.py`两个文件。

- **IP地址混淆**：通过阅读`preprocessing.py`，我们发现脚本中已有名为`mask_ip`的函数，它会将IP地址置零。这表明IP泄露问题在现有流程中已得到处理。

- **端口混淆**：
    - 我们讨论了多种端口混淆策略。代理最初提出了一个基于确定性随机映射的复杂方案。
    - **用户决策**：用户提出一个更简单、更彻底的“归零”方案。我们采纳了这个建议。
    - **实现**：我们为`preprocessing.py`添加了`mask_ports_to_zero`函数，并增加`--mask-ports`命令行标志来控制此功能的开关。

- **基础设施协议过滤**：
    - 这是本次净化工作的关键一步。我们统一了意见，认为应从数据集中彻底剔除`ARP`, `DNS`, `NTP`, `NBNS`, `LLMNR`这些无关协议。
    - **实现**：我们将所有过滤逻辑集中到了`utils.py`的`should_omit_packet`函数中。通过扩展此函数，我们现在可以有效地在预处理的最早阶段就丢弃这些“噪声”数据包。

#### 3. 数据集结构探索

在处理数据泄露问题的过程中，我们对数据集的内部结构进行了对比分析。

- **对比样本**：我们检查了`vpn_aim_chat1b.pcap` (VPN流量) 和 `AUDIO_spotifygateway.pcap` (Tor流量)。
- **结论**：分析证实，VPN和Tor的pcap文件远比非VPN的“纯净”。由于VPN/Tor的隧道封装机制，上述所有基础设施“噪声”协议均不可见。这一发现为后续实验的数据选择提供了重要参考：**优先使用VPN和Tor数据集可以规避大部分数据污染问题**。

#### 4. 训练流程调试

在用户完成了数据预处理后，我们进入了创建训练/测试集的步骤，但遇到了`ValueError: max() arg is an empty sequence`的报错。

- **问题定位**：通过检查`create_train_test_set.py`的日志和代码，我们发现错误是由于Spark未能读取到任何数据，导致标签列表为空。
- **原因分析**：根本原因在于该脚本默认的`json`读取路径模式 (`/*.json.gz`) 过于简单，无法匹配`preprocessing.py`生成的分块文件名（如 `..._part_0000.json.gz`）。
- **解决方案**：我们通过将文件匹配模式修改为更健壮的递归模式 (`/**/*.json.gz`)，解决了这个问题，使得Spark能够正确发现并加载所有数据分块。

#### 总结

经过本次协作，我们：
1.  **确认并解决了**数据集中存在的多类明文信息泄露问题。
2.  **强化了**数据预处理脚本，使其能够过滤无关协议并提供端口混淆选项。
3.  **明确了**不同子数据集（VPN/Tor vs Non-VPN）的纯净度差异。
4.  **修复了**数据加载脚本中的一个关键Bug，打通了从预处理到训练的数据流程。

当前，数据净化和流程调试工作已完成，可以正式进入模型训练阶段。